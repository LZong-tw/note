# TensorFlow和Spark MLlib有什麼區別？



Spark 是为一般的数据处理设计的，并不特定于机器学习。但是使用 MLlib for Spark，也可以在 Spark 上进行机器学习。在基本的设置中，Spark 将模型参数存储在驱动器节点，工作器与驱动器通信从而在每次迭代后更新这些参数。对于大规模部署而言，这些模型参数可能并不适合驱动器，并且会作为一个 RDD 而进行维护更新。这会带来大量额外开销，因为每次迭代都需要创造一个新的 RDD 来保存更新后的模型参数。更新模型涉及到在整个机器/磁盘上重排数据，这就限制了 Spark 的扩展性。这是 Spark 的基本数据流模型(DAG)的不足之处。Spark 并不能很好地支持机器学习所需的迭代

谷歌有一个基于参数服务器模型的分布式机器学习平台 DistBelief。DistBelief 的主要缺陷是：为了编写机器学习应用，需要操作低级代码。谷歌想要自己的所有员工无需精通分布式执行就能编写机器学习代码——基于同样的理由，谷歌为大数据处理编写了 MapReduce 框架。

所以为了实现这一目标，谷歌设计了 TensorFlow。TensorFlow 采用了数据流范式，但是是一种更高级的版本——其中计算图无需是 DAG，而且包含循环且支持可变状态。

TensorFlow 使用节点和边的有向图来表示计算。节点表示计算，状态可变。而边则表示多维数据数组(张量)，在节点之间传输。TensorFlow 需要用户静态声明这种符号计算图，并对该图使用复写和分区(rewrite & partitioning)将其分配到机器上进行分布式执行。(MXNet，尤其是 DyNet 使用了图的动态声明，这改善了编程的难度和灵活性。)



Spark 在两层神经网络上有更大的性能损失。这是因为两层网络需要更多迭代计算。