# Spark與Hadoop關係

###Spark是一個計算框架

###Hadoop是包含計算框架MapReducehe分佈式文件系統HDFS。

 

`Spark是MapReduce的替代方案，而且兼容HDFS、Hive等分佈式存儲系統，可融入Hadoop生態。`

 

###Spark與Hadoop MapReduce優勢如下

####1 中間結果輸出

   MapReduce的計算引擎將中間結果存儲在磁盤上，進行存儲和容錯。

   Spark將執行模型抽象為有向無環圖執行計畫（DAG），這可以將多個Stage的任務串聯或者並行執行，而無須將Stage中間結果輸出到HDFS中。

 

####2 數據格式和內存佈局

  MapReduce  Schema on Read處理方式會引起較大的處理開銷。Spark抽象出分佈式內存存儲結構彈性分佈式數據集RDD，進行數據的存儲。RDD能支持粗粒度寫操作，但是對於讀取操作，RDD可以精確到每條記錄，這使得RDD可以用來作分佈式索引。Spark的特性是能控制數據節點上的分區，用戶可以自定義分區策略，如Hash分區等。Shark 和Spark SQL在Spark的基礎之上實現了列存儲和列存儲壓縮。

 

####3 執行策略

   MapReduce在數據Shuffle之前花費了大量的時間來排序，Spark則可以減輕上述問題帶來的開銷。因為Spark任務在Shuffle中不是所有情景都需要排序，所以支持基於Hash的分佈式聚合，調度中採用更為通用的任務執行計畫圖（DAG），每一輪次的輸出結果在內存緩存。

 

####4 任務調度開銷

    傳統的MapReduce系統，如Hadoop，是為了運行長達數小時的批量作業而設計的，在某些極端情況下，提交一個任務的延遲非常高。

   Spark採用了事件驅動的類庫AKKA來啟動任務，通過線程池復用線程來避免進程或線程啟動和切換開銷。

 

##1、 Spark VSHadoop有哪些異同點？
Hadoop:分佈式批處理計算，強調批處理，常用於數據挖掘和數據分析。

Spark:是一個基於內存計算的開源的集群計算系統，目的是讓數據分析更加快速, Spark 是一種與 Hadoop 相似的開源集群計算環境，但是兩者之間還存在一些不同之處，這些有用的不同之處使 Spark 在某些工作負載方面表現得更加優越，換句話說，Spark 啟用了內存分佈數據集，除了能夠提供交互式查詢外，它還可以優化迭代工作負載。

Spark 是在 Scala 語言中實現的，它將 Scala 用作其應用程序框架。與 Hadoop 不同，Spark 和 Scala 能夠緊密集成，其中的 Scala 可以像操作本地集合對象一樣輕鬆地操作分佈式數據集。

儘管創建 Spark 是為了支持分佈式數據集上的迭代作業，但是實際上它是對 Hadoop 的補充，可以在 Hadoop 文件系統中並行運行。通過名為Mesos的第三方集群框架可以支持此行為。

雖然 Spark 與 Hadoop 有相似之處，但它提供了具有有用差異的一個新的集群計算框架。首先，Spark 是為集群計算中的特定類型的工作負載而設計，即那些在並行操作之間重用工作數據集（比如機器學習算法）的工作負載。為了優化這些類型的工作負載，Spark 引進了內存集群計算的概念，可在內存集群計算中將數據集緩存在內存中，以縮短訪問延遲。

在大數據處理方面相信大家對hadoop已經耳熟能詳，基於GoogleMap/Reduce來實現的Hadoop為開發者提供了map、reduce原語，使並行批處理程序變得非常地簡單和優美。Spark提供的數據集操作類型有很多種，不像Hadoop只提供了Map和Reduce兩種操作。比如map,filter, flatMap,sample, groupByKey, reduceByKey, union,join, cogroup,mapValues, sort,partionBy等多種操作類型，他們把這些操作稱為Transformations。同時還提供Count,collect, reduce, lookup, save等多種actions。這些多種多樣的數據集操作類型，給上層應用者提供了方便。各個處理節點之間的通信模型不再像Hadoop那樣就是唯一的Data Shuffle一種模式。用戶可以命名，物化，控制中間結果的分區等。可以說編程模型比Hadoop更靈活。

 

##2、Spark對於數據處理能力和效率有哪些特色？
Spark提供了高的性能和大數據處理能力，使得用戶可以快速得到反饋體驗更好。另一類應用是做數據挖掘，因為Spark充分利用內存進行緩存，利用DAG消除不必要的步驟，所以比較合適做迭代式的運算。而有相當一部分機器學習算法是通過多次迭代收斂的算法，所以適合用Spark來實現。

Spark配有一個流數據處理模型，與Twitter的 Storm框架相比，Spark採用了一種有趣而且獨特的辦法。Storm基本上是像是放入獨立事務的管道，在其中事務會得到分佈式的處理。相反，Spark採用一個模型收集事務，然後在短時間內（我們假設是5秒）以批處理的方式處理事件。所收集的數據成為他們自己的RDD，然後使用Spark應用程序中常用的一組進行處理。作者聲稱這種模式是在緩慢節點和故障情況下會更加穩健，而且5秒的時間間隔通常對於大多數應用已經足夠快了。這種方法也很好地統一了流式處理與非流式處理部分。